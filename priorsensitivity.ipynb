{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "\n",
    "# Define different prior specifications to test\n",
    "prior_specs = {\n",
    "    \"default_priors\": {\n",
    "        \"mu_alpha_mu\": 0, \"mu_alpha_sigma\": 1,\n",
    "        \"sigma_alpha_sigma\": 1,\n",
    "        \"mu_rho_mu\": 0, \"mu_rho_sigma\": 1,\n",
    "        \"sigma_rho_sigma\": 1,\n",
    "        \"sigma_likelihood_sigma\": 1\n",
    "    },\n",
    "    \"wider_priors\": {\n",
    "        \"mu_alpha_mu\": 0, \"mu_alpha_sigma\": 5, # Wider\n",
    "        \"sigma_alpha_sigma\": 2,               # Wider\n",
    "        \"mu_rho_mu\": 0, \"mu_rho_sigma\": 5,    # Wider\n",
    "        \"sigma_rho_sigma\": 2,                 # Wider\n",
    "        \"sigma_likelihood_sigma\": 2           # Wider\n",
    "    },\n",
    "    \"narrower_priors\": {\n",
    "        \"mu_alpha_mu\": 0, \"mu_alpha_sigma\": 0.5, # Narrower\n",
    "        \"sigma_alpha_sigma\": 0.5,                # Narrower\n",
    "        \"mu_rho_mu\": 0, \"mu_rho_sigma\": 0.5,     # Narrower\n",
    "        \"sigma_rho_sigma\": 0.5,                  # Narrower\n",
    "        \"sigma_likelihood_sigma\": 0.5            # Narrower\n",
    "    },\n",
    "    # Add more scenarios as needed, e.g., priors centered differently\n",
    "    \"shifted_rho_prior\": {\n",
    "        \"mu_alpha_mu\": 0, \"mu_alpha_sigma\": 1,\n",
    "        \"sigma_alpha_sigma\": 1,\n",
    "        \"mu_rho_mu\": 0.5, \"mu_rho_sigma\": 1,  # Shifted mean for rho\n",
    "        \"sigma_rho_sigma\": 1,\n",
    "        \"sigma_likelihood_sigma\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dictionary to store inference data for each prior specification\n",
    "idata_results = {}\n",
    "\n",
    "print(\"--- Starting Prior Sensitivity Analysis ---\")\n",
    "\n",
    "for prior_name, priors in prior_specs.items():\n",
    "    print(f\"\\nRunning model with {prior_name}...\")\n",
    "\n",
    "    with pm.Model(coords=coords) as current_hierarchical_ar_model:\n",
    "        # Hyperparameters for hierarchical prior distributions\n",
    "        # Non-centered parametrization for mu_alpha (overall mean of intercepts)\n",
    "        # and sigma_alpha (standard deviation of intercepts)\n",
    "        mu_alpha_raw = pm.Normal('mu_alpha_raw', mu=priors[\"mu_alpha_mu\"], sigma=priors[\"mu_alpha_sigma\"])\n",
    "        sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=priors[\"sigma_alpha_sigma\"])\n",
    "        mu_alpha = pm.Deterministic('mu_alpha', mu_alpha_raw * sigma_alpha)\n",
    "\n",
    "        # Non-centered parametrization for mu_rho (overall mean of AR coefficients)\n",
    "        # and sigma_rho (standard deviation of AR coefficients)\n",
    "        mu_rho_raw = pm.Normal('mu_rho_raw', mu=priors[\"mu_rho_mu\"], sigma=priors[\"mu_rho_sigma\"])\n",
    "        sigma_rho = pm.HalfNormal('sigma_rho', sigma=priors[\"sigma_rho_sigma\"])\n",
    "        mu_rho = pm.Deterministic('mu_rho', mu_rho_raw * sigma_rho)\n",
    "\n",
    "        # Hierarchical parameters for each state (non-centered parametrization)\n",
    "        # Intercepts for each state\n",
    "        alpha_raw = pm.Normal('alpha_raw', mu=0, sigma=1, dims='state') # These are usually kept standard\n",
    "        alpha = pm.Deterministic('alpha', mu_alpha + alpha_raw * sigma_alpha, dims='state')\n",
    "\n",
    "        # AR(1) coefficients for each state\n",
    "        rho_raw = pm.Normal('rho_raw', mu=0, sigma=1, dims='state') # These are usually kept standard\n",
    "        rho_unconstrained = mu_rho + rho_raw * sigma_rho\n",
    "        rho = pm.Deterministic('rho', pm.Deterministic(\n",
    "            'rho_transformed', pm.math.tanh(rho_unconstrained)), dims='state')\n",
    "\n",
    "        # Standard deviation for the innovations (error term) for each state\n",
    "        sigma = pm.HalfNormal('sigma', sigma=priors[\"sigma_likelihood_sigma\"], dims='state')\n",
    "\n",
    "        # Precompute lagged values for all states\n",
    "        inflation_lagged = inflation_padded[:, :-1]\n",
    "        inflation_current = inflation_padded[:, 1:]\n",
    "            \n",
    "        # Calculate expected mean for each state's time series\n",
    "        mu_inflation = (alpha[:, None] + rho[:, None] * inflation_lagged)\n",
    "\n",
    "        # Filter out NaN values from observed data and corresponding predictions and masks\n",
    "        observed_values_flat = inflation_current[mask[:, 1:]]\n",
    "        mu_inflation_flat = mu_inflation[mask[:, 1:]]\n",
    "            \n",
    "        # Get the corresponding sigma for each valid observed value.\n",
    "        sigma_expanded = np.tile(sigma.eval()[:, None], (1, max_time_len - 1))\n",
    "        sigma_flat = sigma_expanded[mask[:, 1:]]\n",
    "\n",
    "        # Likelihood for the observed inflation values\n",
    "        pm.Normal('inflation_likelihood',\n",
    "                    mu=mu_inflation_flat,\n",
    "                    sigma=sigma_flat,\n",
    "                    observed=observed_values_flat)\n",
    "\n",
    "    with current_hierarchical_ar_model:\n",
    "        idata_results[prior_name] = pm.sample(\n",
    "            draws=1000,   # Reduced draws for faster testing, increase for final analysis\n",
    "            tune=1000,    # Reduced tune for faster testing\n",
    "            chains=2,\n",
    "            cores=2,\n",
    "            random_seed=42,\n",
    "            target_accept=0.9, # Can be slightly less stringent for testing\n",
    "            max_treedepth=10   # Can be slightly less stringent for testing\n",
    "        )\n",
    "\n",
    "# --- Compare Results ---\n",
    "print(\"\\n--- Comparing Posterior Summaries for Different Priors ---\")\n",
    "for prior_name, idata in idata_results.items():\n",
    "    print(f\"\\n--- Results for {prior_name} ---\")\n",
    "    print(pm.summary(idata, var_names=['mu_alpha', 'sigma_alpha', 'mu_rho', 'sigma_rho']))\n",
    "\n",
    "# --- Optional: Visualize Prior vs. Posterior ---\n",
    "# You can also plot prior and posterior distributions to see the influence\n",
    "# of the data vs. the prior. This requires defining the priors as PyMC distributions\n",
    "# in a way that allows sampling them or plotting their PDFs.\n",
    "# For simplicity here, we'll just compare the posterior summaries.\n",
    "\n",
    "# --- Optional: Compare Forecasts ---\n",
    "print(\"\\n--- Comparing Forecasts for Different Priors ---\")\n",
    "all_forecast_dfs = []\n",
    "for prior_name, idata in idata_results.items():\n",
    "    posterior_alpha_sens = idata.posterior[\"alpha\"].mean((\"chain\", \"draw\")).values\n",
    "    posterior_rho_sens = idata.posterior[\"rho\"].mean((\"chain\", \"draw\")).values\n",
    "    \n",
    "    last_observed_values_sens = df_long.groupby('state')['value'].last().values\n",
    "    num_states = len(states)\n",
    "    forecasted_inflation_sens = np.zeros(num_states)\n",
    "    for i in range(num_states):\n",
    "        forecasted_inflation_sens[i] = posterior_alpha_sens[i] + posterior_rho_sens[i] * last_observed_values_sens[i]\n",
    "    \n",
    "    forecast_df_sens = pd.DataFrame({\n",
    "        'State': states,\n",
    "        'Forecasted_Inflation_Next_Period': forecasted_inflation_sens\n",
    "    })\n",
    "    forecast_df_sens.rename(columns={'Forecasted_Inflation_Next_Period': f'Forecast_{prior_name}'}, inplace=True)\n",
    "    all_forecast_dfs.append(forecast_df_sens)\n",
    "\n",
    "# Merge all forecast DataFrames\n",
    "if all_forecast_dfs:\n",
    "    final_forecast_comparison = all_forecast_dfs[0]\n",
    "    for i in range(1, len(all_forecast_dfs)):\n",
    "        final_forecast_comparison = pd.merge(final_forecast_comparison, all_forecast_dfs[i], on='State', how='left')\n",
    "    print(final_forecast_comparison)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
